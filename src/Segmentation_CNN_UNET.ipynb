{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh0jGcm7782s"
      },
      "source": [
        "## Credits and References\n",
        "The code is adapted from the binary classification example as given in the segmentation_models package https://github.com/qubvel/segmentation_models.<br><br>\n",
        "\n",
        "The structure of the code mainly relies on two packages- segmentation-models and albumentations (available to install using pip).<br><br>\n",
        "We use Keras module integrated inside TensorFlow to build the CNN.<br><br>\n",
        "\n",
        "The notebook is inspired by ZeroCostDL4Mic (https://github.com/HenriquesLab/ZeroCostDL4Mic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHunUzEX4mT2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **0. Getting started with this notebook**\n",
        "---\n",
        "This notebook contains two types of cell: text and code.\n",
        "\n",
        "*   **Text** cells are formatted using a simple markup language called Markdown. They can be created by clickin on  ``` + text ``` \n",
        "*   **Code** cells contain either explanatory text or executable code and its output. They can be created by clickin on  ``` + code ```  \n",
        "\n",
        "To execute or run the **Code** cell, click on the play button on the left side of the cell.<br>\n",
        "Double clicking on any cell will toggle the edit and display modes.\n",
        "\n",
        "For more information about these type of cells you can click [here](https://colab.research.google.com/notebooks/basic_features_overview.ipynb). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mojVk8gg4t4z",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **1. Getting Set Up**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Mount the Google drive\n",
        "#@markdown Once mounted, your files can be browsed on the left hand side panel.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BWFdWEQf9WPi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOHwiUVM782x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Set up the IPython notebook\n",
        "\n",
        "from IPython.display import HTML\n",
        "import random\n",
        "\n",
        "def hide_toggle(for_next=False):\n",
        "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
        "    next_cell = this_cell + '.next()'\n",
        "\n",
        "    toggle_text = 'Show/Hide code'  # text shown on toggle link\n",
        "    target_cell = this_cell  # target cell to control with toggle\n",
        "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
        "\n",
        "    if for_next:\n",
        "        target_cell = next_cell\n",
        "        toggle_text += ' next cell'\n",
        "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
        "\n",
        "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
        "\n",
        "    html = \"\"\"\n",
        "        <script>\n",
        "            function {f_name}() {{\n",
        "                {cell_selector}.find('div.input').toggle();\n",
        "            }}\n",
        "\n",
        "            {js_hide_current}\n",
        "        </script>\n",
        "\n",
        "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
        "    \"\"\".format(\n",
        "        f_name=js_f_name,\n",
        "        cell_selector=target_cell,\n",
        "        js_hide_current=js_hide_current, \n",
        "        toggle_text=toggle_text\n",
        "    )\n",
        "\n",
        "    return HTML(html)\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Install segmentation-models package\n",
        "\n",
        "!pip install segmentation-models"
      ],
      "metadata": {
        "id": "-lXawzuo8NcY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Install albumentations package\n",
        "\n",
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "dXk_2SMR8aRw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Set tensorflow's keras module as the framework for the package segmentation-models\n",
        "#@markdown This needs to be done to be able to use segmentation-models with tensorflow-2.4.<br>\n",
        "#@markdown See code to know more.\n",
        "# There is a known problem with efficientnet code and segementation-models code when using keras framework.\n",
        "# This problem is not there for the tensorflow.keras backend.\n",
        "# Set this environment variable to tf.keras so that segmentation-model does not give error by loading keras framework by default.\n",
        "# Otherwise use tensorflow 1.x (2.1 might also work).\n",
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "metadata": {
        "id": "MUCWK5Fn8k3g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koqz6p7bQNVa",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Import packages and check versions\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "import albumentations as A\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tifffile\n",
        "\n",
        "# Optional: Choose tensorflow version\n",
        "#%tensorflow_version 2.x\n",
        "\n",
        "# Check versions\n",
        "print(\"Tensorflow\", tf.__version__)\n",
        "print(\"Albumentations\", A.__version__)\n",
        "print(\"segmentation-models\", sm.__version__)\n",
        "\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRcvDK1dNL13",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **2. Settings for the Colab session**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhgHaFToKheM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "##Confirm the GPU access\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:\n",
        "For more information click [here](https://cloud.google.com/gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ArOgmcoQAtoN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown # Make sure the GPU is available\n",
        "# Make sure the GPU is available\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr5PmaCvPJtp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **3. Input and pre-processing**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izj_PdGU7820"
      },
      "source": [
        "### Set path to training images\n",
        "A set of training images along with corresponding segmentation masks are used to train the model to determine segmentation masks for new images. Both images_dir and masks_dir should contain same number of corresponding images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iTYCOsKE7820"
      },
      "outputs": [],
      "source": [
        "# ------------- Initial user input ------------\n",
        "images_dir = \"/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped1/images\" #@param {type:\"string\"}\n",
        "masks_dir = \"/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped1/masks\"#@param {type:\"string\"}\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vkqSx_PfRnDc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown Create sorted file lists from the input image and mask folders<br>\n",
        "\n",
        "images_filelist = sorted(os.listdir(images_dir))\n",
        "masks_filelist = sorted(os.listdir(masks_dir))\n",
        "\n",
        "print(\"Number of images:\", len(images_filelist))\n",
        "print(\"Number of masks:\", len(masks_filelist))\n",
        "\n",
        "assert(len(images_filelist) == len(masks_filelist))\n",
        "\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoTYly9u7820"
      },
      "source": [
        "### Split the dataset in train, test and validation sets\n",
        "\n",
        "The input images are split in three sets. The train set is used to train the model. Validation set is used to evaluate the model performance during training stage. The test set is kept aside for an additional independent evaluation of the stored model.<br>\n",
        "\n",
        "The fractions of test and validation sets can be given in ``` Test_fraction ``` and ``` Validation_fraction ```.<br>\n",
        "In order to randomize the selection you can use a ``` random_seed ```."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bf0UcAhGQgvz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown Create Train, Validation and Test sets\n",
        "\n",
        "Test_data=0.2 #@param{type:\"number\"}\n",
        "Validation_data=0.3 #@param{type:\"number\"}\n",
        "random_seed=42 #@param{type:\"number\"}\n",
        "\n",
        "# Split training images into train and validation filelists\n",
        "images_filelist = sorted(os.listdir(images_dir))\n",
        "masks_filelist = sorted(os.listdir(masks_dir))\n",
        "\n",
        "train_images_filelist, test_images_filelist, train_masks_filelist, test_masks_filelist = train_test_split(images_filelist, masks_filelist, test_size=Test_data, random_state=random_seed)\n",
        "\n",
        "train_images_filelist, val_images_filelist, train_masks_filelist, val_masks_filelist = train_test_split(train_images_filelist, train_masks_filelist, test_size=Validation_data, random_state=random_seed)\n",
        "\n",
        "print(\"Train images:\", len(train_images_filelist), \", Validation images:\", len(val_images_filelist), \", Test images:\", len(test_images_filelist))\n",
        "print(\"Train masks:\", len(train_masks_filelist), \", Validation masks:\", len(val_masks_filelist), \", Test masks:\", len(test_masks_filelist))\n",
        "\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4lmYe2pPxK5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **4.  Set up data pipelines and visualization methods**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMUuJb_BKPob",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define data loader and visualization functions\n",
        "\n",
        "# helper function for data visualization\n",
        "def visualize(cmap=\"gray\", **images):\n",
        "    #PLot images in one row\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image, cmap=cmap)\n",
        "    plt.show()\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    #Scale image to range [0,1] for correct plot\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "    \n",
        "\n",
        "# classes for data loading and preprocessing\n",
        "class Dataset:\n",
        "    \"\"\" This class is adapted from the binary classification examples in the segmentation_models repository.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "            self,\n",
        "            images_dir=None,\n",
        "            images_filelist=None,\n",
        "            masks_dir=None,\n",
        "            #classes=None,\n",
        "            class_value_pairs=None,\n",
        "            augmentation=None,\n",
        "            preprocessing=None\n",
        "    ):\n",
        "        \n",
        "        self.ids = images_filelist\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        if masks_dir:\n",
        "          self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "          #print(len(self.images_fps), len(self.masks_fps))\n",
        "        else:\n",
        "          self.masks_fps = None\n",
        "\n",
        "        self.classes = []\n",
        "        self.class_values = []\n",
        "        for classname in sorted(class_value_pairs.keys()):\n",
        "          self.classes.append(classname)\n",
        "          self.class_values.append(class_value_pairs[classname])\n",
        "\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #print(self.images_fps[i])\n",
        "        #print(image.shape)\n",
        "\n",
        "        # Process masks\n",
        "        if self.masks_fps:\n",
        "          mask = cv2.imread(self.masks_fps[i], 0)\n",
        "          #print(self.masks_fps[i])\n",
        "\n",
        "          # extract certain classes from mask (e.g. cars)\n",
        "          masks = [(mask == v) for v in self.class_values]\n",
        "          mask = np.stack(masks, axis=-1).astype(float)\n",
        "          #print(np.unique(mask)) [0.0 255.0]\n",
        "          \n",
        "          # add background if mask is not binary\n",
        "          if mask.shape[-1] != 1:\n",
        "              background = 1 - mask.sum(axis=-1, keepdims=True)\n",
        "              mask = np.concatenate((mask, background), axis=-1)\n",
        "        \n",
        "          # apply augmentations\n",
        "          if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "          \n",
        "          # apply preprocessing\n",
        "          if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "          return (image, mask)\n",
        "\n",
        "        else:\n",
        "\n",
        "          # apply augmentations\n",
        "          if self.augmentation:\n",
        "            sample = self.augmentation(image=image)\n",
        "            image = sample['image']\n",
        "\n",
        "          # apply preprocessing\n",
        "          if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image)\n",
        "            image = sample['image']\n",
        "\n",
        "          return (image,)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    \n",
        "    \n",
        "class Dataloader(tf.keras.utils.Sequence):\n",
        "    \"\"\"This class is adapted from the binary classification examples in the segmentation_models repository.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        \n",
        "        # transpose list of lists\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        return tuple(batch)\n",
        "    \n",
        "    def __len__(self):\n",
        "        # Returns the number of batches per epoch\n",
        "        return len(self.indexes) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indices on each epoch\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvOROO7A3v0c",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define augmentation functions\n",
        "\n",
        "# These functions are adapted from the binary classification examples in the segmentation_models repository.\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def round_clip_0_1(x, **kwargs):\n",
        "    return x.round().clip(0, 1)\n",
        "\n",
        "# define heavy augmentations\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "\n",
        "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
        "\n",
        "        A.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
        "        A.RandomCrop(height=320, width=320, always_apply=True),\n",
        "\n",
        "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
        "        A.IAAPerspective(p=0.5),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.CLAHE(p=1),\n",
        "                A.RandomBrightness(p=1),\n",
        "                A.RandomGamma(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.IAASharpen(p=1),\n",
        "                A.Blur(blur_limit=3, p=1),\n",
        "                A.MotionBlur(blur_limit=3, p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.RandomContrast(p=1),\n",
        "                A.HueSaturationValue(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "        A.Lambda(mask=round_clip_0_1)\n",
        "    ]\n",
        "    return A.Compose(train_transform)\n",
        "\n",
        "#Stretching\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    # Add paddings to make image shape divisible by 32\n",
        "    test_transform = [\n",
        "        #A.PadIfNeeded(384, 480)\n",
        "        #A.PadIfNeeded(320, 320),\n",
        "        #A.RandomCrop(height=320, width=320, always_apply=True),\n",
        "        A.Resize(320, 320, always_apply=True)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    # Build preprocessing transform\n",
        "        \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)\n",
        "\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MXeM9Qp7821"
      },
      "source": [
        "> ### Define what to read from masks<br>\n",
        "The ```Segment_name``` can be any name which you want to give to your segmented object.<br>\n",
        "The ```Segment_value``` should be the intensity value corresponding to that segment. You can choose any non-zero value from the mask's unique values. See the next cell.<br>\n",
        "Please note that a wrong segment value (which is not there in the mask) will lead to a blank mask."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Check unique values in the masks\n",
        "#@markdown Use a non-zero value from below as ```Segment_value```\n",
        "\n",
        "v = []\n",
        "for fname in masks_filelist:\n",
        "  m = cv2.imread(masks_dir+\"/\"+fname, 0)\n",
        "  v += list(np.unique(m))\n",
        "\n",
        "print('\\nMask unique values:', \", \".join([str(x) for x in np.unique(np.array(v))]))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vfxuLkkWmaXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Define the segment label to read\n",
        "Segment_name='cell' #@param {type:\"string\"}\n",
        "\n",
        "Segment_value=128 #@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WjAfEJx5n9El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vCjxgsQKS9D",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load data and visualize (without augmentation)<br>\n",
        "#@markdown If you see a correct image-mask pair after running this cell, then the dataset is loaded correctly.\n",
        "# helper function for data visualization\n",
        "\n",
        "# Showing images from dataset\n",
        "dataset = Dataset(images_dir=images_dir, images_filelist=train_images_filelist, \n",
        "                  masks_dir=masks_dir, class_value_pairs={Segment_name:Segment_value})\n",
        "\n",
        "image, mask = dataset[0] # get some sample\n",
        "print(\"Image shape:\", image.shape, \"  Mask shape:\", mask.shape, \"Image min, max:\", image.max(),\",\",image.max())\n",
        "\n",
        "visualize(cmap=\"gray\",\n",
        "    image=image,\n",
        "    cell_mask=mask[..., 0].squeeze()\n",
        "    #background_mask=mask[..., 2].squeeze()\n",
        ")\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta3_shOYFZnK",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load data and visualize (with augmentation)\n",
        "#@markdown If you see a correct image-mask pair after running this cell, then the dataset is loaded correctly.\n",
        "\n",
        "dataset = Dataset(images_dir=images_dir,\n",
        "                  images_filelist=train_images_filelist,\n",
        "                  masks_dir=masks_dir,\n",
        "                  class_value_pairs={Segment_name:Segment_value},\n",
        "                  augmentation=get_training_augmentation())\n",
        "\n",
        "image, mask = dataset[10] # get some sample\n",
        "print(\"Image shape:\", image.shape, \"  Mask shape:\", mask.shape, \"Image min, max:\", image.min(),\",\",image.max())\n",
        "visualize(cmap=\"gray\",\n",
        "    image=image, \n",
        "    cell_mask=mask[..., 0].squeeze()\n",
        "    #background_mask=mask[..., 2].squeeze()\n",
        ")\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRrK9q9J5XSe",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **5. Define U-net parameters**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCTLuEp5Af0p",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "\n",
        "\n",
        "*   **ENCODER_WEIGHTS** – None (for random initialization), imagenet (for pre-training on ImageNet). Using ImageNet weights to start the training process may result in faster training.\n",
        "*   **BACKBONE** – name of classification model to be used as feature extractor to build segmentation model. Last dense layers are not considered. A few possibilities are- ```vgg16```, ```efficientnetb3```, ```efficientnetb7```,```inceptionv3```, ```resnet50```.\n",
        "*   **BATCH_SIZE** - The number of samples that will be used by the network to at in a single step. Larger batch sizes generalize better in general. However, batch size can also be very small, for example- 2, if the number of training samples is small.\n",
        "*   **LEARNING RATE (LR)** - Factor to control how much the model weights are updated to account for the estimated error. Faster learning rates (higher value) result in faster training process but may produce unstable results or poor learning. Slower learning rates (lower value) can make the training process very slow, sometimes not reaching the optimum in reasonable time.\n",
        "*   **EPOCHS** - The number of epochs is the number of times the training happens on the full training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2QjLCk-05eEc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown ### Set parameters<br>\n",
        "#@markdown Note that the Segment_name and Segment_value are the same parameters which we tested before for verification of the dataset creation.\n",
        "\n",
        "ENCODER_WEIGHTS = 'imagenet' #@param {type:\"string\"}\n",
        "BACKBONE = 'inceptionv3'  #@param {type:\"string\"}\n",
        "BATCH_SIZE = 2 #@param {type:\"number\"}\n",
        "Segment_name = 'cell' #@param {type:\"string\"}\n",
        "Segment_value = 128 #@param {type:\"number\"}\n",
        "class_value_pairs={Segment_name:Segment_value}\n",
        "CLASSES = list(class_value_pairs.keys())\n",
        "LR = 0.0001 #@param {type:\"number\"}\n",
        "EPOCHS = 20 #@param {type:\"number\"}\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# define network parameters\n",
        "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
        "activation = 'sigmoid' if n_classes == 1 else 'softmax'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3HObB18Vo0v",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **6. Create model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSEzr4kHUvhD",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Create a UNET model using the parameters defined above\n",
        "model = sm.Unet(BACKBONE,\n",
        "                classes=n_classes,\n",
        "                encoder_weights=ENCODER_WEIGHTS,\n",
        "                activation=activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNa5J4z5XZeC",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define optimizer\n",
        "\n",
        "optim = tf.keras.optimizers.Adam(LR)\n",
        "print(\"Optimizer:\", optim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zerba3PXayp",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define segmentation models losses\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "print(\"Loss:\", total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oHm41GMXMH-",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Compile the model\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "model.compile(optim, total_loss, metrics)\n",
        "print(\"Model compiled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb_oDzOHYRb6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **7. Setup datasets and output directories**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7nU0S9wYj-K",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Define training and validation datasets\n",
        "\n",
        "# Dataset for train images\n",
        "train_dataset = Dataset(\n",
        "    images_dir=images_dir,\n",
        "    images_filelist=train_images_filelist,\n",
        "    masks_dir=masks_dir,\n",
        "    class_value_pairs={Segment_name:Segment_value},\n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "# Dataset for validation images\n",
        "valid_dataset = Dataset(\n",
        "    images_dir=images_dir,\n",
        "    images_filelist=val_images_filelist,\n",
        "    masks_dir=masks_dir,\n",
        "    class_value_pairs={Segment_name:Segment_value},\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "train_dataloader = Dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = Dataloader(valid_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# check shapes for errors\n",
        "assert train_dataloader[0][0].shape == (BATCH_SIZE, 320, 320, 3)\n",
        "assert train_dataloader[0][1].shape == (BATCH_SIZE, 320, 320, n_classes)\n",
        "\n",
        "print(\"Training dataset:\", len(train_dataloader.indexes), \"files.\")\n",
        "print(\"Validation dataset:\", len(valid_dataloader.indexes), \"files.\")\n",
        "\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IRISAL27a5vb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown  ### Define output folder for trained model and set up model callbacks for learning rate scheduling and best checkpoints saving\n",
        "models_dir = \"/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped1\" #@param {type:\"string\"}\n",
        "name_CNN =  '/model_1.h5' #@param {type:\"string\"}\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(models_dir+name_CNN,\n",
        "                                       save_weights_only=True,\n",
        "                                       save_best_only=True,\n",
        "                                       mode='min'),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyNrHpBNbmCZ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **8. Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R7E9UWPbqUB",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Train the model (This may take a long time)\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataloader,\n",
        "    steps_per_epoch=len(train_dataloader),\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=valid_dataloader,\n",
        "    validation_steps=len(valid_dataloader)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q741diVwbx1U",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **9. Plot results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fRc-ChA9b4Ry",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown Plot 1: train and validation iou_score values (iou: Intesection over Union)<br>\n",
        "#@markdown Plot 2: Plot train and validation loss values\n",
        "#@markdown Gradual lowering of values for further epochs may suggest that the training process is proceeding correctly.<br>\n",
        "#@markdown Sudden jumps in the iou scores or the loss values may indicate unstable learning.\n",
        "\n",
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model iou_score')\n",
        "plt.ylabel('iou_score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        " \n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtYjrQXlp_Uw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **10. Model Evaluation**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Load test dataset\n",
        "\n",
        "Segment_name='cell' #@param {type:\"string\"}\n",
        "\n",
        "Segment_value=128 #@param {type:\"number\"}\n",
        "\n",
        "print(\"Number of samples in test dataset:\", len(test_images_filelist))\n",
        "\n",
        "test_dataset = Dataset(\n",
        "    images_dir=images_dir,\n",
        "    images_filelist=test_images_filelist,\n",
        "    masks_dir=masks_dir,\n",
        "    class_value_pairs={Segment_name:Segment_value},\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "# Optional visualize to confirme that the correct dataset is loaded.\n",
        "image, mask = test_dataset[0] # get some sample\n",
        "print(\"Image shape:\", image.shape, \"  Mask shape:\", mask.shape, \"Image min, max:\", image.min(),\",\",image.max())\n",
        "visualize(cmap=\"gray\",\n",
        "    image=image, \n",
        "    cell_mask=mask[..., 0].squeeze()\n",
        "    #background_mask=mask[..., 2].squeeze()\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "test_dataloader = Dataloader(test_dataset, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d8uNqiRkl-Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cpUqgjpTqa3j",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load best weights from the saved model and evaluate on the test dataset<br>\n",
        "#@markdown You only have to give the path to the saved model (for example, the '.h5' file in a previous step).\n",
        "\n",
        "best_weights= '/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped1/model_1.h5'#@param {type:\"string\"}\n",
        "model.load_weights(best_weights)\n",
        "\n",
        "print(\"Model evaluation:\")\n",
        "scores = model.evaluate(test_dataloader)\n",
        "\n",
        "print(\"Loss: {:.5}\".format(scores[0]))\n",
        "for metric, value in zip(metrics, scores[1:]):\n",
        "    print(\"mean {}: {:.5}\".format(metric.__name__, value))\n",
        "    \n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu85VvCFX9FY",
        "pycharm": {
          "name": "#%%\n"
        },
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Visualize test results for random samples from test dataset\n",
        "#@markdown Image: Original image, Gt Mask: Groundtruth Mask, Pr Mask: Predicted Mask\n",
        "\n",
        "num_samples = 3 #@param {type:\"number\"}\n",
        "\n",
        "ids = np.random.choice(np.arange(len(test_dataset)), size=num_samples)\n",
        "\n",
        "for i in ids:\n",
        "  image, gt_mask = test_dataset[i]\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  pr_mask = model.predict(image).round()\n",
        "  print(\"Image shape:\", image.shape, \"  Mask shape:\", mask.shape, \"Image min, max:\", image.max(),\",\",image.max())\n",
        "  visualize(cmap=\"gray\",\n",
        "            image=image[0][:,:,0],\n",
        "            gt_mask=gt_mask[..., 0].squeeze(),\n",
        "            pr_mask=pr_mask[..., 0].squeeze()\n",
        "            #background_mask=mask[..., 2].squeeze()\n",
        "            )\n",
        "\n",
        "hide_toggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFfLcHZnnB51",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# **11. Inference**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on new images and save predicted masks"
      ],
      "metadata": {
        "id": "7-OCtZIEwsO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Load best weights from the saved model and evaluate on the test dataset<br>\n",
        "#@markdown You only have to give the path to the saved model (for example, the '.h5' file in a previous step).\n",
        "\n",
        "best_weights= '/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped1/model_1.h5'#@param {type:\"string\"}\n",
        "model.load_weights(best_weights)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rvrjdoq9xjjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Set up input folder for the new images\n",
        "new_images_dir = \"/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/C2-113_16-46_cropped3\"#@param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iCaHDVUyqpdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Create dataset for new images\n",
        "\n",
        "new_images_filelist = sorted(os.listdir(new_images_dir))\n",
        "\n",
        "new_dataset = Dataset(\n",
        "    images_dir=new_images_dir,\n",
        "    images_filelist=new_images_filelist,\n",
        "    #classes=CLASSES,\n",
        "    class_value_pairs={Segment_name:Segment_value},\n",
        "    augmentation=get_validation_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input)\n",
        ")\n",
        "\n",
        "# Debugging: Check images\n",
        "# t = new_dataloader.__getitem__(5)\n",
        "# type(t), len(t), len(t[0]), t[0][0][:,:,0].shape, t[0][0][:,:,0].max()\n",
        "\n",
        "new_dataloader = Dataloader(new_dataset, batch_size=1, shuffle=False)\n",
        "print(\"Number of images in new dataset:\", len(new_dataloader.indexes))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YUcSGKinsnKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Try predictions on samples from new images\n",
        "\n",
        "num_random_samples = 2#@param {type:\"number\"}\n",
        "\n",
        "ids = np.random.choice(np.arange(len(new_dataset)), size=num_random_samples)\n",
        "\n",
        "for i in ids:\n",
        "  image, = new_dataset[i]\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  pr_mask = model.predict(image).round()\n",
        "  print(i, image.shape, pr_mask.shape, image.max())\n",
        "  visualize(cmap=\"gray\",\n",
        "            image=image[0][:,:,0],\n",
        "            pr_mask=pr_mask[..., 0].squeeze()\n",
        "            #background_mask=mask[..., 2].squeeze()\n",
        "            )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dbAEqWvJsBCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Set output folder\n",
        "output_dir = '/content/drive/MyDrive/chiaraZurzoloLab/Jaouen/unet_segmentation/datasets/temp_output'#@param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YF3ZYFE0u2Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Predict and save new image masks\n",
        "for i in range(0, len(new_dataloader.indexes)):\n",
        "  image, = new_dataset[i]\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  pr_mask = model.predict(image).round()\n",
        "  pr_mask=pr_mask[..., 0].squeeze()\n",
        "  print(pr_mask.shape)\n",
        "  cv2.imwrite(output_dir + \"/img_\" + str(i) + \".png\", pr_mask)\n",
        "  "
      ],
      "metadata": {
        "cellView": "form",
        "id": "K8sRmmBBs67V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyzUl5ZSzMus"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}